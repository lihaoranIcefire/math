<!doctype html><html><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1"><title>MLNotes</title><style>/* copy from https://github.com/sindresorhus/github-markdown-css/ */

html,body{background-color: #2d2d2d;}

.markdown-body {
  -ms-text-size-adjust: 100%;
  -webkit-text-size-adjust: 100%;
  line-height: 1.5;
  color: #cccccc;
  font-family: -apple-system,BlinkMacSystemFont,Segoe UI,Helvetica,Arial,sans-serif,Apple Color Emoji,Segoe UI Emoji;
  font-size: 16px;
  line-height: 1.5;
  word-wrap: break-word;
}

.markdown-body .octicon {
  display: inline-block;
  fill: currentColor;
  vertical-align: text-bottom;
}

.markdown-body figure{margin:0;padding:0; display:table;}
.markdown-body figure figcaption{font-size:92%; text-align:center; color:#999999;}

.markdown-body .anchor {
  float: left;
  line-height: 1;
  margin-left: -20px;
  padding-right: 4px;
}

.markdown-body .anchor:focus {
  outline: none;
}

.markdown-body h1 .octicon-link,
.markdown-body h2 .octicon-link,
.markdown-body h3 .octicon-link,
.markdown-body h4 .octicon-link,
.markdown-body h5 .octicon-link,
.markdown-body h6 .octicon-link {
  color: #66cccc;
  vertical-align: middle;
  visibility: hidden;
}

.markdown-body h1:hover .anchor,
.markdown-body h2:hover .anchor,
.markdown-body h3:hover .anchor,
.markdown-body h4:hover .anchor,
.markdown-body h5:hover .anchor,
.markdown-body h6:hover .anchor {
  text-decoration: none;
}

.markdown-body details {
  display: block;
}

.markdown-body summary {
  display: list-item;
}

.markdown-body a {
  background-color: initial;
}

.markdown-body a:active,
.markdown-body a:hover {
  outline-width: 0;
}

.markdown-body strong {
  font-weight: inherit;
  font-weight: bolder;
}
.markdown-body strong{
  color: #f99157;
}
.markdown-body em{
  color: #ffcc66;
}

.markdown-body h1 {
  font-size: 2em;
  margin: .67em 0;
}

.markdown-body img {
  border-style: none;
}

.markdown-body code,
.markdown-body kbd,
.markdown-body pre {
  font-family: monospace,monospace;
  font-size: 1em;
}

.markdown-body hr {
  box-sizing: initial;
  height: 0;
  overflow: visible;
}

.markdown-body input {
  font: inherit;
  margin: 0;
}

.markdown-body input {
  overflow: visible;
}

.markdown-body [type=checkbox] {
  box-sizing: border-box;
  padding: 0;
}

.markdown-body * {
  box-sizing: border-box;
}

.markdown-body input {
  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
}

.markdown-body a {
  color: #99cc99;
  text-decoration: none;
}
.markdown-body mjx-container[jax="SVG"] > svg a{fill:#99cc99;stroke: #99cc99;}

.markdown-body a:hover {
  text-decoration: underline;
}

.markdown-body strong {
  font-weight: 600;
}

.markdown-body hr:after,
.markdown-body hr:before {
  display: table;
  content: "";
}

.markdown-body hr:after {
  clear: both;
}

.markdown-body table {
  border-spacing: 0;
  border-collapse: collapse;
}

.markdown-body td,
.markdown-body th {
  padding: 0;
}

.markdown-body details summary {
  cursor: pointer;
}

.markdown-body kbd {
  display: inline-block;
  padding: 3px 5px;
  font: 12px SFMono-Regular,Consolas,Liberation Mono,Menlo,monospace;
  line-height: 12px;
  color: #999999;
  vertical-align: middle;
  background-color: #333333;
  border: 1px solid #494949;
  border-radius: 3px;
}

.markdown-body h1,
.markdown-body h2,
.markdown-body h3,
.markdown-body h4,
.markdown-body h5,
.markdown-body h6 {
  margin-top: 0;
  margin-bottom: 0;
}

.markdown-body h1 {
  font-size: 32px;
}

.markdown-body h1,
.markdown-body h2 {
  font-weight: 600;
}

.markdown-body h2 {
  font-size: 24px;
}

.markdown-body h3 {
  font-size: 20px;
}

.markdown-body h3,
.markdown-body h4 {
  font-weight: 600;
}

.markdown-body h4 {
  font-size: 16px;
}

.markdown-body h5 {
  font-size: 14px;
}

.markdown-body h5,
.markdown-body h6 {
  font-weight: 600;
}

.markdown-body h6 {
  font-size: 12px;
}

.markdown-body p {
  margin-top: 0;
  margin-bottom: 10px;
}

.markdown-body blockquote {
  margin: 0;
}

.markdown-body ol,
.markdown-body ul {
  padding-left: 0;
  margin-top: 0;
  margin-bottom: 0;
}

.markdown-body ol ol,
.markdown-body ul ol {
  list-style-type: lower-roman;
}

.markdown-body ol ol ol,
.markdown-body ol ul ol,
.markdown-body ul ol ol,
.markdown-body ul ul ol {
  list-style-type: lower-alpha;
}

.markdown-body dd {
  margin-left: 0;
}

.markdown-body code,
.markdown-body pre {
  font-family: SFMono-Regular,Consolas,Liberation Mono,Menlo,monospace;
  font-size: 12px;
}

.markdown-body pre {
  margin-top: 0;
  margin-bottom: 0;
}

.markdown-body input::-webkit-inner-spin-button,
.markdown-body input::-webkit-outer-spin-button {
  margin: 0;
  -webkit-appearance: none;
  appearance: none;
}

.markdown-body:after,
.markdown-body:before {
  display: table;
  content: "";
}

.markdown-body:after {
  clear: both;
}

.markdown-body>:first-child {
  margin-top: 0!important;
}

.markdown-body>:last-child {
  margin-bottom: 0!important;
}

.markdown-body a:not([href]) {
  color: inherit;
  text-decoration: none;
}

.markdown-body blockquote,
.markdown-body details,
.markdown-body dl,
.markdown-body ol,
.markdown-body p,
.markdown-body pre,
.markdown-body table,
.markdown-body ul {
  margin-top: 0;
  margin-bottom: 16px;
}

.markdown-body hr {
  height: .25em;
  padding: 0;
  margin: 24px 0;
  background-color: #494949;
  border: 0;
}

.markdown-body blockquote {
  padding: 0 1em;
  color: #9b9b9b;
  border-left: .25em solid #f2777a;
}

.markdown-body blockquote>:first-child {
  margin-top: 0;
}

.markdown-body blockquote>:last-child {
  margin-bottom: 0;
}

.markdown-body h1,
.markdown-body h2,
.markdown-body h3,
.markdown-body h4,
.markdown-body h5,
.markdown-body h6 {
  margin-top: 24px;
  margin-bottom: 16px;
  font-weight: 600;
  line-height: 1.25;
}

.markdown-body h1 {
  font-size: 2em;
}

.markdown-body h1,
.markdown-body h2 {
  padding-bottom: .3em;
  border-bottom: 1px solid #434343;
  color: #66cccc;
}

.markdown-body h2 {
  font-size: 1.5em;
  color: #66cccc;
}

.markdown-body h3 {
  font-size: 1.25em;
  color: #66cccc;
}

.markdown-body h4 {
  font-size: 1em;
  color: #66cccc;
}

.markdown-body h5 {
  font-size: .875em;
  color: #66cccc;
}

.markdown-body h6 {
  font-size: .85em;
  color: #66cccc;
}

.markdown-body ol,
.markdown-body ul {
  padding-left: 2em;
}

.markdown-body ol ol,
.markdown-body ol ul,
.markdown-body ul ol,
.markdown-body ul ul {
  margin-top: 0;
  margin-bottom: 0;
}

.markdown-body li {
  word-wrap: break-all;
}

.markdown-body li>p {
  margin-top: 16px;
}

.markdown-body li+li {
  margin-top: .25em;
}

.markdown-body dl {
  padding: 0;
}

.markdown-body dl dt {
  padding: 0;
  margin-top: 16px;
  font-size: 1em;
  font-style: italic;
  font-weight: 600;
}

.markdown-body dl dd {
  padding: 0 16px;
  margin-bottom: 16px;
}

.markdown-body table {
  display: block;
  width: 100%;
  overflow: auto;
}

.markdown-body table th {
  font-weight: 600;
}

.markdown-body table td,
.markdown-body table th {
  padding: 6px 13px;
  border: 1px solid #717171;
}

.markdown-body table tr {
  background-color: #2d2d2d;
  border-top: 1px solid #717171;
}

.markdown-body table th {
  background-color: #434343;
}

.markdown-body table tr:nth-child(2n) {
  background-color: #323232;
}

.markdown-body img,.markdown-body video {
  max-width: 100%;
  box-sizing: initial;
}

.markdown-body img[align=right] {
  padding-left: 20px;
}

.markdown-body img[align=left] {
  padding-right: 20px;
}

.markdown-body code {
  padding: .2em .4em;
  margin: 0;
  font-size: 85%;
  background-color: #333333;
  color: #999999;
  border-radius: 3px;
}

.markdown-body pre {
  word-wrap: normal;
}

.markdown-body pre>code {
  padding: 0;
  margin: 0;
   font-size: 100%;
  word-break: normal;
  white-space: pre;
  background: transparent;
  border: 0;
}

.markdown-body .highlight {
  margin-bottom: 16px;
}

.markdown-body .highlight pre {
  margin-bottom: 0;
  word-break: normal;
}

.markdown-body .highlight pre,
.markdown-body pre {
  padding: 16px;
  overflow: auto;
  font-size: 85%;
  line-height: 1.45;
  background-color: #333333;
  border-radius: 3px;
}

.markdown-body pre code {
  display: inline;
  max-width: auto;
  padding: 0;
  margin: 0;
  overflow: visible;
  line-height: inherit;
  word-wrap: normal;
  background-color: initial;
  border: 0;
  color: #999999;
}

.markdown-body .task-list-item {
  list-style-type: none;
}

.markdown-body .task-list-item+.task-list-item {
  margin-top: 3px;
}

.markdown-body .task-list-item input {
  margin: 0 .2em .25em -1.6em;
  vertical-align: middle;
}

.markdown-body .task-list-item input[type="checkbox"]{
-webkit-appearance: none;-moz-appearance: none;appearance: none;
width: 14px; height: 14px;outline: none;
border: 1px solid #99cc99;border-radius: 2px; 
}
.markdown-body .task-list-item input[type="checkbox"]:checked {
  background:no-repeat center/80% url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20viewBox%3D%220%200%20512%20512%22%3E%3Cpath%20fill%3D%22%2399cc99%22%20d%3D%22M173.898%20439.404l-166.4-166.4c-9.997-9.997-9.997-26.206%200-36.204l36.203-36.204c9.997-9.998%2026.207-9.998%2036.204%200L192%20312.69%20432.095%2072.596c9.997-9.997%2026.207-9.997%2036.204%200l36.203%2036.204c9.997%209.997%209.997%2026.206%200%2036.204l-294.4%20294.401c-9.998%209.997-26.207%209.997-36.204-.001z%22%2F%3E%3C%2Fsvg%3E") ;
}

.markdown-body section.footnotes{
    margin-top:48px;
    border-top:solid 1px #494949;
    padding-top:0px;
}

@media (prefers-color-scheme: dark) {
  .markdown-body mark{color: #111;}
}

/* PrismJS 1.23.0
https://prismjs.com/download.html#themes=prism&languages=markup+css+clike+javascript */
/**
 * prism.js default theme for JavaScript, CSS and HTML
 * Based on dabblet (http://dabblet.com)
 * @author Lea Verou
 */


code[class*="language-"],
pre[class*="language-"] {
    color: black;
    background: none;
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
    text-align: left;
    white-space: pre;
    word-spacing: normal;
    word-break: normal;
    word-wrap: normal;
    -moz-tab-size: 4;
    -o-tab-size: 4;
    tab-size: 4;

    -webkit-hyphens: none;
    -moz-hyphens: none;
    -ms-hyphens: none;
    hyphens: none;
}

@media print {
    code[class*="language-"],
    pre[class*="language-"] {
        text-shadow: none;
    }
}

/* Code blocks */
pre[class*="language-"] {
    padding: 1em;
    margin: .5em 0;
    overflow: auto;
}

:not(pre) > code[class*="language-"],
pre[class*="language-"] {
    background-color: #333333;
}

/* Inline code */
:not(pre) > code[class*="language-"] {
    padding: .1em;
    border-radius: .3em;
    white-space: normal;
}

.token.comment,
.token.prolog,
.token.doctype,
.token.cdata {
    color: #48be66;
}

.token.punctuation {
    color: #8b86c9;
}

.token.namespace {
    opacity: .7;
}

.token.property,
.token.tag,
.token.boolean,
.token.number,
.token.constant,
.token.symbol,
.token.deleted {
    color: #8b86c9;
}

.token.selector,
.token.attr-name,
.token.string,
.token.char,
.token.builtin,
.token.inserted {
    color: #e6424b;
}

.token.operator,
.token.entity,
.token.url,
.language-css .token.string,
.style .token.string {
    color: #$$codeBlockColor$$;
}

.token.atrule,
.token.attr-value,
.token.keyword {
    color: #c33795;
}

.token.function,
.token.class-name {
    color: #67878e;
}

.token.regex,
.token.important,
.token.variable {
    color: #d38e63;
}

.token.important,
.token.bold {
    font-weight: bold;
}
.token.italic {
    font-style: italic;
}

.token.entity {
    cursor: help;
}


pre[class*="language-"].line-numbers {
  position: relative;
  padding-left: 3.8em;
  counter-reset: linenumber;
}

pre[class*="language-"].line-numbers > code {
  position: relative;
  white-space: inherit;
}

.line-numbers .line-numbers-rows {
  position: absolute;
  pointer-events: none;
  top: 0;
  font-size: 100%;
  left: -3.8em;
  width: 3em; /* works for line-numbers below 1000 lines */
  letter-spacing: -1px;
  border-right: 1px solid #6b6b6b;

  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;

}

  .line-numbers-rows > span {
    display: block;
    counter-increment: linenumber;
  }

    .line-numbers-rows > span:before {
      content: counter(linenumber);
      color: #6b6b6b;
      display: block;
      padding-right: 0.8em;
      text-align: right;
    }


</style><style>.mweb-charts{background:#fff;}
body{ box-sizing: border-box;
    margin: 0 auto;}
@media print{
    pre, code, pre code {
     overflow: visible !important;
     white-space: pre-wrap !important;       /* css-3 */
     white-space: -moz-pre-wrap !important;  /* Mozilla, since 1999 */
     white-space: -pre-wrap !important;      /* Opera 4-6 */
     white-space: -o-pre-wrap !important;    /* Opera 7 */
     word-wrap: break-word !important;       /* Internet Explorer 5.5+ */
    }
    html,body{margin:0;padding:4px;}
}



div.code-toolbar {
  position: relative;
}

div.code-toolbar > .toolbar {
  position: absolute;
  z-index: 10;
  top: .3em;
  right: .2em;
  transition: opacity 0.3s ease-in-out;
  opacity: 0;
}

div.code-toolbar:hover > .toolbar {
  opacity: 1;
}

/* Separate line b/c rules are thrown out if selector is invalid.
   IE11 and old Edge versions don't support :focus-within. */
div.code-toolbar:focus-within > .toolbar {
  opacity: 1;
}

div.code-toolbar > .toolbar > .toolbar-item {
  display: inline-block;
}

div.code-toolbar > .toolbar > .toolbar-item > a {
  cursor: pointer;
}

div.code-toolbar > .toolbar > .toolbar-item > button {
  background: none;
  border: 0;
  color: inherit;
  font: inherit;
  line-height: normal;
  overflow: visible;
  padding: 0;
  -webkit-user-select: none; /* for button */
  -moz-user-select: none;
  -ms-user-select: none;
}

div.code-toolbar > .toolbar > .toolbar-item > a,
div.code-toolbar > .toolbar > .toolbar-item > button,
div.code-toolbar > .toolbar > .toolbar-item > span {
  color: inherit;
  font-size: .8em;
  padding: 4px .5em;
  background: #f5f2f0;
  background: rgba(224, 224, 224, 0.4);
  box-shadow: 0 2px 0 0 rgba(0,0,0,0.2);
  border-radius: .5em;
}

div.code-toolbar > .toolbar > .toolbar-item > a:hover,
div.code-toolbar > .toolbar > .toolbar-item > a:focus,
div.code-toolbar > .toolbar > .toolbar-item > button:hover,
div.code-toolbar > .toolbar > .toolbar-item > button:focus,
div.code-toolbar > .toolbar > .toolbar-item > span:hover,
div.code-toolbar > .toolbar > .toolbar-item > span:focus {
  color: inherit;
  text-decoration: none;
}
</style><script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/prism.min.js"></script><script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/plugins/line-numbers/prism-line-numbers.min.js"></script><script>!function(){if("undefined"!=typeof Prism&&"undefined"!=typeof document){var e=[],t={},n=function(){};Prism.plugins.toolbar={};var a=Prism.plugins.toolbar.registerButton=function(n,a){var r;r="function"==typeof a?a:function(e){var t;return"function"==typeof a.onClick?((t=document.createElement("button")).type="button",t.addEventListener("click",(function(){a.onClick.call(this,e)}))):"string"==typeof a.url?(t=document.createElement("a")).href=a.url:t=document.createElement("span"),a.className&&t.classList.add(a.className),t.textContent=a.text,t},n in t?console.warn('There is a button with the key "'+n+'" registered already.'):e.push(t[n]=r)},r=Prism.plugins.toolbar.hook=function(a){var r=a.element.parentNode;var l=a.element.classList;if(l.contains('language-mermaid') || l.contains('language-echarts') || l.contains('language-plantuml')){return;} if(r&&/pre/i.test(r.nodeName)&&!r.parentNode.classList.contains("code-toolbar")){var o=document.createElement("div");o.classList.add("code-toolbar"),r.parentNode.insertBefore(o,r),o.appendChild(r);var i=document.createElement("div");i.classList.add("toolbar");var l=e,d=function(e){for(;e;){var t=e.getAttribute("data-toolbar-order");if(null!=t)return(t=t.trim()).length?t.split(/\s*,\s*/g):[];e=e.parentElement}}(a.element);d&&(l=d.map((function(e){return t[e]||n}))),l.forEach((function(e){var t=e(a);if(t){var n=document.createElement("div");n.classList.add("toolbar-item"),n.appendChild(t),i.appendChild(n)}})),o.appendChild(i)}};a("label",(function(e){var t=e.element.parentNode;if(t&&/pre/i.test(t.nodeName)&&t.hasAttribute("data-label")){var n,a,r=t.getAttribute("data-label");try{a=document.querySelector("template#"+r)}catch(e){}return a?n=a.content:(t.hasAttribute("data-url")?(n=document.createElement("a")).href=t.getAttribute("data-url"):n=document.createElement("span"),n.textContent=r),n}})),Prism.hooks.add("complete",r)}}();</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/plugins/toolbar/prism-toolbar.min.css"><script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/plugins/copy-to-clipboard/prism-copy-to-clipboard.min.js"></script><script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/plugins/autoloader/prism-autoloader.min.js"></script><style>div.code-toolbar > .toolbar > .toolbar-item > a, div.code-toolbar > .toolbar > .toolbar-item > button, div.code-toolbar > .toolbar > .toolbar-item > span {padding: 4px .5em; background: #f5f2f0; background: rgba(224, 224, 224, 0.4);}</style><script>window.MathJax = {     tex: { tags: 'ams', displayMath: [ ['\\[', '\\]'] ] } ,     startup: {     pageReady() {       return MathJax.startup.defaultPageReady().then(function () {          window.mweb_mathjax_ready_val = 'yes';          if(window.mweb_mathjax_ready !== undefined){ mweb_mathjax_ready(); }       });     }   }};document.addEventListener('DOMContentLoaded', function(event) {    if (typeof Prism != 'undefined') {         Prism.highlightAll();     }});window.mweb_mathjax_ready_val = '';function theMWebMathJaxRenderIsReady(key){ return window.mweb_mathjax_ready_val; }</script><script>window.MathJax = { tex: { tags: 'ams', displayMath: [ ['\\[', '\\]'] ] } }; </script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"></script> <style>body{max-width:808px; padding:24px;}</style></head><body><div id='markdown_content' class='markdown-body'><h1><a id="machine-learning-notes" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Machine Learning Notes</h1>
<h2><a id="table-of-contents" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Table of contents</h2>
<ol>
<li><a href="#DataCleaning">Data Cleaning</a></li>
<li><a href="#DataPreprocessing">Data Preprocessing</a>
<ol>
<li><a href="#DataScalingandStandardizing">Data scaling and standardizing</a></li>
<li><a href="#Imputation">Imputation</a></li>
<li><a href="#Pipeline">Pipeline</a></li>
</ol>
</li>
<li><a href="#SupervisedLearning">Supervised Learning</a>
<ol>
<li><a href="#BiasVarianceTradeOff">Bias-variance trade-off</a></li>
<li><a href="#kFoldCrossValidation&amp;GridSearch">\(k\)-fold cross validation &amp; grid search</a></li>
<li><a href="#GradientDescent">Gradient descent</a></li>
<li><a href="#ConfusionMatrix">Confusion matrix</a></li>
<li><a href="#kNN">\(k\)-nearest neighbors</a></li>
<li><a href="#LogisticRegression">Logistic regression</a></li>
<li><a href="#SupportedVectorMachine">Supported vector machine</a></li>
<li><a href="#BayesBasedClassifiers">Bayes' based classifiers</a></li>
<li><a href="#DecisionTrees">Decision trees</a></li>
<li><a href="#TimeSeries">Time series</a></li>
</ol>
</li>
<li><a href="#UnsupervisedLearning">Unsupervised Learning</a></li>
</ol>
<h2><a id="data-cleaning-a-name-datacleaning-a" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Data Cleaning <a name="DataCleaning"></a></h2>
<h2><a id="data-preprocessing-a-name-datapreprocessing-a" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Data Preprocessing <a name="DataPreprocessing"></a></h2>
<h3><a id="data-scaling-and-standardizing-a-name-datascalingandstandardizing-a" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Data scaling And standardizing <a name="DataScalingandStandardizing"></a></h3>
\[x_i\leftarrow\dfrac{x_i-\mu}{\sigma}
\]
<h4><a id="pros-cons" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Pros &amp; Cons</h4>
<p>Dataset will be normalized, avoid unbalanced dataset</p>
<h4><a id="usage" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Usage</h4>
<p><code>sklearn.StandardScaler</code></p>
<h3><a id="imputation-a-name-imputation-a" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Imputation <a name="Imputation"></a></h3>
<p>The process of replace missing values is known as data <em>imputation</em></p>
<h4><a id="examples" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Examples</h4>
<ul>
<li>Constant imputation: replace with contants</li>
<li>Linear interpolation/Regression Imputation: replace using a regression model</li>
<li>median/mean/mode/(sample statistic) imputation: replace with median/mean/mode/(sample statistic)</li>
<li>forward/backward fill: replace with previous/next value</li>
<li>KNN: replace using the mode the closest \(k\) neighbors</li>
</ul>
<h6><a id="remark" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Remark</h6>
<p>You should not use the labels or test data set to imputate training data set</p>
<h3><a id="pipelines-a-name-pipeline-a" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Pipelines <a name="Pipeline"></a></h3>
<h5><a id="definition" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Definition</h5>
<p>A <em>pipeline</em> is a series of data processing components arranged sequentially, each component in the pipeline performs a specific task.</p>
<h6><a id="pros-cons" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Pros &amp; Cons</h6>
<p>This process streamlines the workflow, makes it easier to combine and expriment different algorithms and models.</p>
<h6><a id="example" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Example</h6>
<p>Learning cubic polynomial \(y=\beta_0+\beta_1x+\beta_2x^2+\beta_3x^3+\epsilon\)</p>
<pre><code class="language-plain_text">from sklearn.pipeline import Pipeline
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model.LinearRegression

pipe = Pipeline([
    ('poly', PolynomialFeatures(3, interaction_only=False, include_bias=False)),
    ('reg', LinearRegression(copy_X=True))
])
</code></pre>
<p><code>PolynomialFeatures</code> generate higher powers \(x^n\) from \(x\).</p>
<h2><a id="supervised-learning-a-name-supervisedlearning-a" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Supervised Learning <a name="SupervisedLearning"></a></h2>
<p>Given dataset \(\{(\mathbf x_i,\mathbf y_i)\}_{i=1}^N\), where \(\mathbf x_i\) are <em>feature vectors</em>, its entries are called <em>features</em>, and \(\mathbf y_i\) are <em>labels</em> or <em>predictions</em>. Assume \(\mathbf y=f(\mathbf x)+\mathbf\epsilon\) where \(f\) is a continuous function and \(\mathbf\epsilon\) is random noise (\(E(\mathbf \epsilon)=\mathbf 0\)). <em>Supervised learning</em> is the process of using a machine learning algorithm to &quot;learn&quot; \(f\) from the dataset, and make predictions.</p>
<h3><a id="bias-variance-trade-off-a-name-biasvariancetradeoff-a" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Bias-variance trade-off <a name="BiasVarianceTradeOff"></a></h3>
<p>Suppose \(y = f(x) + \epsilon\) is the real function (\(E[\epsilon]=0\), \(Var[\epsilon]=\sigma^2\)) and \(\hat f(x)\) is the model. Then the <em>total error</em> is equal to</p>
\[\begin{align*}
E[(y-\hat f)^2] &amp;= E[y^2]-2E[y\hat f]+E[\hat f^2]\\
&amp;= E[(f+\epsilon)^2]-2E[(f+\epsilon)\hat f]+V[\hat f]+E[\hat f]^2\\
&amp;= E[f^2]+2E[f]E[\epsilon]+E[\epsilon^2]-2E[f]E[\hat f]-2E[\epsilon]E[\hat f]+V[\hat f]+E[\hat f]^2\\
&amp;= E[f^2]+\sigma^2-2E[f]E[\hat f]+V[\hat f]+E[\hat f]^2\\
&amp;= E[(f-\hat f)^2]+V[\hat f]+\sigma^2\\
&amp;= E[(f-\hat f)^2]+V[\hat f]+\sigma^2\\
\end{align*}
\]
<p>Here \(\sigma^2\) is referred to as the <em>irreducible error</em>, so we have the simplified version</p>
\[\text{total error = bias$^2$ + Variance + irreducible error}
\]
<h6><a id="remark" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Remark</h6>
<p>When underfitting the model, the model tends to be too simple so that the bias is huge. When overfitting the model (e.g., using a linear equation approximate a quadratic), the model tends to be too complex, so the variance within is great (e.g., use a high polynomial to approximate a linear relation with small random noise). Therefore, there is no way to get rid of both, one has to make the tradeoff between bias and variance so that both aren't too significant.</p>
<h3><a id="k-fold-cross-validation-grid-search-a-name-kfoldcrossvalidation-gridsearch-a" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>\(k\)-fold cross validation &amp; grid search <a name="kFoldCrossValidation&GridSearch"></a></h3>
<ol>
<li><em>\(k\)-fold cross validation</em> divide the dataset into \(k\) subsets. Train the model on \(k-1\) subsets independently \(k\) times by single out each as the validation set. And eventually take the average of the parameters.</li>
<li><em>Grid search</em> provide an array of values for each parameter and test model with every value and choose the best one.</li>
</ol>
<h4><a id="usage" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Usage</h4>
<pre><code class="language-plain_text">from sklearn.neighbors import KNeighborsRegressor
from sklearn.model_selection import KFold
from sklearn.metrics import mean_squared_error

GridSearchCV(
    cv = KFold(n_splits=5, random_state=30293, shuffle=True),
    estimator = KNeighborsRegressor(),
    param_grid = {
        'n_neighbors': range(1, 50),
        'weights': ['uniform', 'distance']
    },
    scoring = 'neg_mean_squared_error'
)
</code></pre>
<h6><a id="remark" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Remark</h6>
<p>When should you not use cross-validation, and use simple validation instead?</p>
<ol>
<li>Dataset size is too small. This can lead to deficiencies in both model fitting and estimation.</li>
<li>Model training time is too long. It might not worth the time.</li>
</ol>
<h3><a id="gradient-descent-a-name-gradientdescent-a" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Gradient descent <a name="GradientDescent"></a></h3>
<p>The method of <em>gradient descent</em> is to decrease the loss function \(\ell\) by \(\beta\leftarrow\beta-\alpha\nabla(\beta)\).<br />
Some common adjustments are</p>
<ol>
<li><em>Mini-batch gradient descent</em>: instead of use the entire dataset, cycling through mini batches to generate gradients.</li>
<li><em>Stochastic gradient descent</em>: Randomly generates learning rates \(\alpha\) each time.
<ul>
<li>Pros: Avoid of being stuck in a local minimum.</li>
</ul>
</li>
</ol>
<h4><a id="comparisons-of-common-gradient-descent-methods" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Comparisons of common gradient descent methods</h4>
<ul>
<li><em>Stochastic gradient descent(SGD)</em> is to update the parameter according to individual gradient<br />
Gradient descent is
\[\theta_{t+1}=\theta_t-\lambda\cdot\nabla L(\theta_t)
\]
And SGD is when \(L(\theta)=\dfrac{1}{N}\sum_iL_i(\theta)\)</li>
<li><em>Momentum</em> \(v\) is defined by
\[\begin{cases}
v_{t+1}=\beta\cdot v_t+(1-\beta)\cdot\nabla L(\theta_t)\\
\theta_{t+1}=\theta_t-\lambda\cdot v_{t+1}
\end{cases}
\]
This includes the &quot;inertia&quot; from the previous momentums and gradients, it helps accelerate convergence in the direction of persistent gradient, and reduce oscillations.</li>
<li><em>Adaptive gradient(Adagrad)</em> is mathematically described by
\[\begin{cases}
G_{t+1}=G_t+|\nabla L(\theta_t)|^2\\
\theta_{t+1}=\theta_t-\dfrac{\lambda}{\sqrt{G_{t+1}+\epsilon}}\cdot \nabla L(\theta_{t+1})
\end{cases}
\]
\(G_t\) is the accumulated squared gradients (like the second momentum). This method ensures that the learning rate doesn't get too small when having really large gradients. This method is good with sparse data but might overly reduce learning rate when encountering some frequently occuring features with large gradients.</li>
<li><em>Root mean squared propagation(RMSprop)</em> is slightly changing Adagrad
\[\begin{cases}
G_{t+1}=\beta\cdot G_t+(1-\beta)|\nabla L(\theta_t)|^2\\
\theta_{t+1}=\theta_t-\dfrac{\lambda}{\sqrt{G_{t+1}+\epsilon}}\cdot \nabla L(\theta_{t+1})
\end{cases}
\]
This method helps mitigate the problem of diminishing learning rate</li>
<li><em>Adaptive moment estimate(Adam)</em> combines momentum and RMSProp
\[\begin{cases}
m_{t+1}=\beta_1\cdot m_t+(1-\beta_1)\cdot\nabla L(\theta_t)\\
v_{t+1}=\beta_2v_t+|\nabla L(\theta_t)|^2\\
\hat m_{t+1} = \dfrac{m_t}{1-\beta_1^{t+1}}\\
\hat v_{t+1} = \dfrac{v_t}{1-\beta_2^{t+1}}\\
\theta_{t+1}=\theta_t-\dfrac{\lambda}{\sqrt{\hat v_{t+1}+\epsilon}}\cdot \hat m_{t+1}
\end{cases}
\]
The normalization prevents bias from early initialization (for example, \(m_0=v_0=0\), dividing \(1-\beta_1,1-\beta_2\) could make them less biased, as time progress, \(\beta^t\) has exponential decay and goes to 0 and has no effect in normalizing).</li>
</ul>
<h3><a id="confusion-matrix-a-name-confusionmatrix-a" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Confusion matrix <a name="ConfusionMatrix"></a></h3>
<p>The <em>confusion matrix</em> is the \(2\times2\) contingency table, where the rows are the predicted values, and columns are the actual values.</p>
<table>
<thead>
<tr>
<th></th>
<th>Positive</th>
<th>Negative</th>
</tr>
</thead>
<tbody>
<tr>
<td>Positive</td>
<td>TP</td>
<td>FP</td>
</tr>
<tr>
<td>Negative</td>
<td>FN</td>
<td>TN</td>
</tr>
</tbody>
</table>
<p>We define</p>
<ul>
<li><em>Accuracy</em> = \(\dfrac{TP+TN}{TP+FP+FN+TN}\)<br />
Accuracy is used if the dataset is balanced and equally distributed, e.g. spam detection</li>
<li><em>Precision</em> = \(\dfrac{TP}{TP+FP}\)<br />
Precision is used if the cost for false positive is high, e.g. Fraud detection</li>
<li><em>Recall(Sensitivity)</em> = \(\dfrac{TP}{TP+FN}\)<br />
Recall is used if the cost for false negative is high, e.g. disease detection</li>
<li><em>Specificity</em> = \(\dfrac{TN}{TN+FP}\)</li>
<li><em>F1 score</em> = harmonic mean of Precision and Recall, i.e.</li>
</ul>
\[\text{F1 score} = \dfrac{2}{\dfrac{1}{\text{Precision}}+\dfrac{1}{\text{Recall}}} = 2\dfrac{\text{Precision}\times\text{Recall}}{\text{Precision}+\text{Recall}}
\]
<p>F1 score is the single metric of both the precision and recall which balances the Precision-Recall tradeoff by taking both into account, especially if there is an uneven class distribution, e.g. search engine ranking for relevance.</p>
<p><em>Receivers operating characteristic curve (ROC)</em> is the plot of recall against (1-specificity), and the diagonal line means a total random model.</p>
<p><em>Area under ROC (AUROC)</em> measures a comprehensive classifier's performance, if it is 0.5, and it is like random, if it is 1, then it is outstanding discrimination. For example, predicting customer churn.</p>
<p><em>Coefficient of determination (\(R^2\))</em> is defined to be \(1-\dfrac{\sum_i(y_i-\hat y_i)^2}{\sum_i(y_i-\bar y)^2}\). If \(R^2=0\), it means the model have worst predictions since it is a constant average prediction, if \(R^2=1\), then the model is accurate.</p>
<p>GAIN/LIFT charts</p>
<h3><a id="k-nearest-neighbors-a-name-knn-a" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>\(k\)-nearest neighbors <a name="kNN"></a></h3>
<p>The <em>\(k\)-nearest neighbors</em> algorithm assigns the most likely label from the nearest neighbors.</p>
<h3><a id="logistic-regression-a-name-logisticregression-a" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Logistic regression <a name="LogisticRegression"></a></h3>
<p><em>Logistic regression</em> used in binary classification by \(p(x)=\dfrac{1}{1+e^{-\beta x}}\).</p>
<h4><a id="interaction-terms-in-linear-regression" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Interaction terms in linear regression</h4>
<p>When you have categorical vairables, you should add interaction terms since it might has a impact on other variables.</p>
<h3><a id="supported-vector-machine-a-name-supportedvectormachine-a" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Supported vector machine <a name="SupportedVectorMachine"></a></h3>
<p>In binary classification, given a dataset \(\{(\mathbf x_i,y_i)\}_{i=1}^N\), where \(y_i=\pm1\) is the label. Naively, <em>supported vector machine</em> is used to find a border that maximize the margin between two classes.</p>
<h4><a id="hard-margin" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Hard margin</h4>
<p>If the data is linear separable, we wish to find a hyperplane \(\mathbf w\cdot\mathbf x-b=\mathbf0\) that separate these two classes with maximal margin. Equivalently, it is to solve the following problem: Find \(\mathbf w\) and \(b\) that minimize \(\|\mathbf w\|_2^2\) and subject to</p>
\[y_i(\mathbf w\cdot\mathbf x_i-b)\geq 1
\]
<p>The geometric interpretation depends on the fact:</p>
\[\text{The distance between the origin and the plane $\mathbf w\cdot\mathbf x-b=0$ is $\frac{|b|}{\|\mathbf w\|_2}$}
\]
<p>We want to choose \(\mathbf w,b\) such that \(\mathbf w\cdot\mathbf x-b=1\), \(\mathbf w\cdot\mathbf x-b=-1\) barely touches two classes. So the margin between each class and the border would be \(\frac{1}{\|\mathbf w\|_2}\). Note that this max-margin hyperplane is completely determined by those \(\mathbf x_i\) that lie nearset to it, they are called <em>support vectors</em>.</p>
<h4><a id="hinge-loss" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Hinge loss</h4>
<p>The <em>hinge loss</em> is a function like \(\ell(y)=\max(0,1-t\cdot y)\).</p>
<h4><a id="soft-margin" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Soft margin</h4>
<p>If the dataset is not linearly separable, we introduce the <em>hinge function</em> \(\max(0,1-y_i(\mathbf w\cdot\mathbf x_i-b))\), this penalize data on the wrong side of the margin. We can define a loss function</p>
\[\lambda\|\mathbf w\|_2^2+\frac{1}{N}\sum_{i=1}^N\max(0,1-y_i(\mathbf w\cdot\mathbf x_i-b))
\]
<p>If \(\lambda\) is small, then it is basically hard-margin SVM. A soft-margin optimization problem could be to minimize \(\lambda\|\mathbf w\|_2^2+\frac{1}{N}\sum_{i=1}^N\zeta_i\) subject to</p>
\[y_i(\mathbf w\cdot\mathbf x_i-b)\geq 1-\zeta_i,\quad \zeta_i\geq0
\]
<h4><a id="nonlinear-kernels" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Nonlinear kernels</h4>
<p>Sometimes it is very hard to separate data, we consider transformations \(\varphi\) that takes \(\mathbf x_i\) into higher dimensional spaces (even infinite dimensions!). And if we make sufficiently good choices, we don't need to care what \(\varphi\) really does and we simply need to know what \(\kappa(\mathbf x_i,\mathbf x_j)=\varphi(\mathbf x_i)\cdot\varphi(\mathbf x_j)\) is, \(\kappa\) is called <em>kernel</em>. Common examples are</p>
<ol>
<li>Linear: \(\kappa(\mathbf x_i,\mathbf x_j)=\mathbf x_i\cdot\mathbf x_j\).</li>
<li>Polynomlial: \(\kappa(\mathbf x_i,\mathbf x_j)=(\mathbf x_i\cdot\mathbf x_j+r)^d\).<br />
Note that for example if we choose \(\varphi(x_1,x_2)=(x_1^2,\sqrt2x_1x_2,x_2^2)\), then
\[\varphi(\mathbf x)\cdot\varphi(\mathbf y)=x_1^2x_2^+2x_1x_2y_2y_2+y_1^2y_2^2=(x_1y_1+x_2y_2)^2=(\mathbf x\cdot\mathbf y)^2
\]
</li>
<li>Gaussian Radial Kernel: \(\kappa(\mathbf x_i,\mathbf x_j)=\exp(-\gamma\|\mathbf x_i-\mathbf x_j\|_2^2)\).</li>
<li>Sigmoid: \(\kappa(\mathbf x_i,\mathbf x_j)=\tanh(\gamma\mathbf x_i\cdot\mathbf x_j+r)\).</li>
</ol>
<p>We can solve the dual optimization problem.</p>
<h3><a id="bayes-based-classifiers-a-name-bayesbasedclassifiers-a" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Bayes' based classifiers <a name="BayesBasedClassifiers"></a></h3>
<h4><a id="linear-discriminant-analysis-lda" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Linear discriminant analysis (LDA)</h4>
<p>Assume \(X|y=c\sim\mathcal N(\mu_c,\sigma^2)\), in the case where \(X\) has one feature, we have</p>
\[f_c(x)=\frac{1}{\sqrt{2\pi}\sigma}\exp\left(-\frac{(x-\mu_c)^2}{2\sigma^2}\right)
\]
<p>Then Bayes' rule tells us</p>
\[P(y=c|X)=\frac{\pi_c\frac{1}{\sqrt{2\pi}\sigma}\exp\left(-\frac{(x-\mu_c)^2}{2\sigma^2}\right)}{\sum_{l=1}^C\pi_l\frac{1}{\sqrt{2\pi}\sigma}\exp\left(-\frac{(x-\mu_l)^2}{2\sigma^2}\right)}
\]
<p>Here \(\pi_c\) denotes \(P(y=c)\). So we could estimate</p>
\[\hat\mu_c=\frac{1}{N_c}\sum_{y_i=c}X_i
\]
\[\hat\sigma^2=\frac{1}{N-C}\sum_{c=1}^C\sum_{y_i=c}(X_i-\hat\mu_c)^2
\]
<p>We make predictions by choosing \(c\) rendering maximum likelihood \(P(y=c|X)\), this is equivalent to choose largest <em>discriminant function</em></p>
\[\delta_c(X)=X\frac{\mu_c}{\sigma^2}-\frac{\mu_c^2}{2\sigma^2}+\log(\pi_c)
\]
<p>Here we should use \(\hat\mu_c,\hat\sigma\). In the case where \(X\) has \(m\) features, we have \(X|y=c\sim\mathcal N(\mu_c,\Sigma)\), and</p>
\[f_c(\mathbf x)=\frac{1}{(2\pi)^{m/2}|\Sigma|^{1/2}}\exp\left(-\frac{1}{2}(\mathbf x-\mu_c)^T\Sigma^{-1}(\mathbf x-\mu_c)\right)
\]
<p>And the discriminant function will be</p>
\[\delta_c(X)X^T\Sigma^{-1}\mu_c-\frac{1}{2}\mu_c^T\Sigma^{-1}\mu_c+\log(\pi_c)
\]
<h4><a id="quadratic-discriminant-analysis-qda" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Quadratic discriminant analysis (QDA)</h4>
<p>Assume \(X|y=c\sim\mathcal N(\mu_c,\Sigma_c)\), we get discriminant</p>
\[\begin{align*}
\delta_c(X)&amp; = -\frac{1}{2} \left( X - \mu_c \right)^T \Sigma_c^{-1}  \left(X- \mu_c  \right) - \frac{1}{2}\log\left(|\Sigma_c| \right) + \log(\pi_c)\\
&amp;= -\frac{1}{2} X^{T} \sigma^{-1}_c X + X^{T} \sigma^{-1}_c \mu_c - \frac{1}{2} \mu_c^T \sigma_c^{-1} \mu_c - \frac{1}{2}\log\left(|\Sigma_c| \right) + \log(\pi_c)
\end{align*}
\]
<h4><a id="naive-bayes-classifier" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Naive Bayes classifier</h4>
<p>Assume for each given class \(c\), each of the \(m\) features are independent, we then have</p>
\[f_c(X)=f^{(1)}_c(X_1)\cdots f^{(m)}_c(X_m)
\]
<p>Then by Bayes rule</p>
\[P(y=c|X)=\frac{\pi_cf^{(1)}_c(X_1)\cdots f^{(m)}_c(X_m)}{\sum_{l=1}^C\pi_lf^{(1)}_l(X_1)\cdots f^{(m)}_l(X_m)}
\]
<p>To estimate \(f^{i}_c\) we assume some kind of distribution and hten estimate the parameters</p>
<ul>
<li>If \(X_i\) are quantitative, we assume it is a normal distribution</li>
<li>If \(X_i\) are categorical, we assume it is a Bernouli distribution</li>
</ul>
<h4><a id="pros-cons" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Pros &amp; Cons</h4>
<ol>
<li>LDA works better for smaller datasets and QDA works for large datasets</li>
<li>LDA works better if the data can be mostly separated by linear decision boundaries. QDA works better if the decision boundaries are not linear.</li>
<li>If we have really small amount of data, we can use naive Bayes model. This in general a decent classifier.</li>
</ol>
<h3><a id="decision-trees-a-name-decisiontrees-a" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Decision trees <a name="DecisionTrees"></a></h3>
<h4><a id="pros-cons" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Pros &amp; Cons</h4>
<ul>
<li>Pros
<ul>
<li>Very fast and very needs little data preprocessing</li>
</ul>
</li>
<li>Cons
<ul>
<li>This algorithm is greedy, so might not create an optimal tree</li>
<li>Decision trees have orthogonal boundaries, which might not be ideal</li>
<li>Decision trees are sensitive to training data</li>
</ul>
</li>
</ul>
<h4><a id="gini-impurity" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Gini impurity</h4>
<p><em>Gini impurity</em> \(I_G\) is defined by</p>
\[I_G(p)=\sum_ip_i(1-p_i)=\sum_i(p_i-p_i^2)=1-\sum_ip_i^2
\]
<p>\(I_G(p)\) is between 0 and 1, if \(I_G(p)=0\), then it is of a single class, if it is \(1-\dfrac{1}{N}\), it is evenly distributed.</p>
<h4><a id="cross-entropy" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Cross entropy</h4>
<p>The information content of an event \(E\) is quantified as \(\log\left(\dfrac{1}{p(E)}\right)=-\log(p(E))\).</p>
<p>Suppose \(P,Q\) are two random variables, \(P\) is the actual distribution and \(Q\) is the prediction</p>
<p><em>Entropy</em> of \(P\) is defined to be</p>
\[H(P)=-E_P[\log P]=-\sum_ip_i\log(p_i)
\]
<p><em>Cross-entropy loss</em> is defined to be</p>
\[H(P,Q)=-E_P[\log Q]=-\sum_ip_i\log(q_i)
\]
<p>which measures the discrepancy using \(Q\) as predictions given the actual distribution is \(P\).</p>
<p><em>Relative entropy (KL convergence)</em> is defined to be</p>
\[D_{KL}(P||Q)=\sum_ip_i\log\left(\dfrac{p_i}{q_i}\right)=H(P,Q)-H(P)
\]
<p>This is always nonnegative (<em>Gibb's inequality</em>) since</p>
\[\begin{align*}
-D_{KL}(P||Q)&amp;=\sum_ip_i\ln\left(\dfrac{q_i}{p_i}\right)\\
&amp;\leq\sum_ip_i\left(\dfrac{q_i}{p_i}-1\right)\\
&amp;=\sum_iq_i-\sum_ip_i\\
&amp;=0
\end{align*}
\]
<p>So the minimum of the cross entropy \(H(P)\) is attained \(\iff P=Q\)</p>
<p>Note that cross entropy and relative entropy measures the same because the entropy of \(P\) is fixed.</p>
<h4><a id="cart-algorithm" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>CART algorithm</h4>
<p>The <em>CART</em> (Classification and Regression Trees) algorithm is a decision tree-based algorithm that can be used for both classification and regression problems in machine learning. It works by recursively partitioning the training data into smaller subsets using binary splits.</p>
<h4><a id="random-forest" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Random Forest</h4>
<p>The <em>random forest</em> model is made by building many different decision trees. These trees are made &quot;different&quot; through a variety of random perturbations. Finally take the average of all trees.</p>
<h4><a id="bagging-and-pasting" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Bagging and pasting</h4>
<p><em>Bagging</em> and <em>pasting</em> are two ways to generate random forest. Where bagging is with replacement and pasting is without replacement. In general people tend to use bagging as a default. The reason is that bagging requires less data.</p>
<h4><a id="boosting" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Boosting</h4>
<p>A statistical learning algorithm is said to be a</p>
<ul>
<li><em>weak learner</em> if it does slightly better thant random guessing.</li>
<li><em>strong learner</em> if can be made arbitrarily close the true relationship</li>
</ul>
<p>Thanks to PAC (Probably approximately correct) learnability, one can show that there exists <em>boosting</em> algorithms that can turn weak learners into strong learners.</p>
<p>For example a decision tree with a single layer (decision stump) is a weak learner, whereas a decision tree is a strong leaner.</p>
<h4><a id="adaptive-boosting" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Adaptive boosting</h4>
<p><em>Adaptive boosting</em> is building stronger learners iteratively by learning the weakness of the previous weak leaner. Suppose we have iteratively built up the first \(j\) weak learners, we now construct the \(j+1\)-th weak learner. Suppose the prediction of \(y_i\) by the \(j\)-th weak learner is \(\hat y^{(j)}_i\), and assume the current weight assigned to \(y_i\) is \(w_i\), then we calculate the <em>weighted error rate</em> = 1 - weighted accuracy</p>
\[r_j=\frac{\sum_{\hat y^{(j)}_i\neq y_i}w_i}{\sum_{i=1}^Nw_i}
\]
<p>We then calculate the wieght assigned to the \(j\)-th weak learner</p>
\[\alpha_j=\eta\log\left(\frac{1-r_j}{r_j}\right)
\]
<p>\(\eta\) is the learning rate. Finally we update the traning sample weights for \(j+1\)-th weak learner</p>
\[w_i\leftarrow\begin{cases}
w_i, \hat y^{(j)}_i=y_i\\
w_i\exp(\alpha_j), \hat y^{(j)}_i\neq y_i
\end{cases}
\]
<h4><a id="gradient-boosting" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Gradient boosting</h4>
<p><em>Gradient boosting</em> is iteratively building an ensenble of weak learners where a learner is directly trained to model the previous learner's errors. Suppose we have built the first \(j\) weak learners, we build the \(j+1\)-th weak learner by trained to learn to predict ther residual \(r_j\) of the previous learner, and set \(h_{j+1}(X)=\hat r_j\) as its estimate of the residual, and then calculate the residual of this weak learner \(r_{j+1}=r_j-h_j(X)\). By the end the strong learner \(h(X)\) found is the sum of all the weak learners \(h_j(X)\).</p>
<p><em>XGBoost (extreme Gradient boosting)</em> is a specific implementation of gradient boosting that is optimized for performance, efficiency, and scalability. So it is very popular.</p>
<h3><a id="time-series-a-name-timeseries-a" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Time series <a name="TimeSeries"></a></h3>
<ol>
<li>A <em>time series</em> is a sequence of data points \(\{(\mathbf x_t,y_t)\}\) where \(\mathbf x_t\) is a collection of features, \(y_t\) is a numeric variable of interest, and \(t\) stands for time.</li>
<li>Given a time series \(\{(\mathbf x_{t_i},y_{t_i})\}_{i=1}^n\), a <em>forecast</em> is \(y_t=f(\mathbf x_t,t|\{y_\tau\}_{\tau&lt;t})+\epsilon_t\).</li>
<li>A model for time series is a series of random variables \(\{y_t\}_{t\in T}\), where \(y_t\) only depends on \(\mathbf x_t,t\), and \(\mathbf x_t\) is a collection of features that only depends on \(t\).</li>
</ol>
<h4><a id="baseline-forecasting-models" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Baseline forecasting models</h4>
<ol>
<li>without trend nor seasonality
<ul>
<li><em>Average forecast</em> assumes \(y_t\) are independent and identically distributed. The forecast \(y_t=\dfrac{1}{n}\sum\limits_{i=1}^ny_i+\epsilon\) takes the historical average.</li>
<li><em>Naive forecast</em> assumes \(y_t\) is a random walk. The forecast \(y_{t}=y_n+\epsilon\) only uses the last observation.</li>
</ul>
</li>
<li>with trend but not seasonality
<ul>
<li>Linear trend forecast assumes \(E(y_t)=\beta t\). The forecast is \(y_t=\hat\beta t+\epsilon\) with \(\hat\beta\) being the average of first differences \(y_{i+1}-y_i\). An intercept term can be added.</li>
<li>Random walk with drift assumes \(y_{t+1}=y_t+\beta+\epsilon\). The forecast is \(y_t=y_n+\hat\beta(t-n)+\epsilon\) with \(\hat\beta\) being the average of first differences.</li>
</ul>
</li>
<li>with seasonality but not trend
<ul>
<li>Seasonal average forecast assume \(\{y_{r+km}\}_{k}\) are independent and identically distributed for each \(0\leq r&lt;m\). The forecast is</li>
</ul>
\[y_t=\dfrac{1}{\lfloor n/m\rfloor+1}\sum\limits_{k=0}^{\lfloor n/m\rfloor}y_{r+km},\quad r=t\mod m
\]
<ul>
<li>Seasonal naive forecast assumes \(\{y_{r+km}\}_{k}\) are random walks. The forecast is</li>
</ul>
\[y_t=y_\tau+\epsilon,\quad \tau=t-\left(\left\lfloor\frac{t-n}{m}\right\rfloor+1\right)m
\]
</li>
</ol>
<h4><a id="stationary-series" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Stationary series</h4>
<ol>
<li>A time series is <em>strictly stationary</em> if \(y_{t_1},\cdots,y_{t_n}\) and \(y_{t_1+\tau},\cdots,y_{t_n+\tau}\) has the same joint probability distribution for any \(n,\tau,t_1,\cdots, t_n\). In particular, we would have
<ul>
<li>\(E(y_t)=\mu\) and \(\operatorname{Var}(y_t)=\sigma^2\).</li>
<li>The joint distribution of \(y_{t_1},\cdots,y_{t_n}\) only depends on \(t_{i+1}-t_i\), these are referred to as the <em>lags</em>.</li>
</ul>
</li>
<li>A time series is <em>stationary</em> if
\[E(y_t)=\mu,\qquad\operatorname{Cov}(y_t,y_\tau)=\gamma(\tau)
\]
here \(\gamma(\tau)\) is called the <em>autovariance</em>, and note that \(\operatorname{Var}(y_t)=\gamma(0)=\sigma^2\).</li>
</ol>
<h5><a id="examples" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Examples</h5>
<ol>
<li><em>White noise</em> is a stationary time series with zero mean constant variance and zero correlation between different times.</li>
<li>The first differences \(y_{t+1}-y_t\) of a random walk \(y_{t+1}=y_t+\epsilon\).</li>
<li>A moving average process \(y_t=\beta_0\epsilon_t+\beta_1\epsilon_{t-1}+\cdots+\beta_q\epsilon_{t-q}\).</li>
</ol>
<h5><a id="differencing" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Differencing</h5>
<p>The \(d\)-th differences \(\nabla^{d}y_t=\nabla^{d-1}y_t-\nabla^{d-1}y_{t-1}\) often produce a stationary series from a non-stationary one.</p>
<h4><a id="arima" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>ARIMA</h4>
<ol>
<li>A time series is <em>autoregressive</em> (AR) of order \(p\) if
\[y_t=\alpha_1y_{t-1}+\cdots+\alpha_py_{t-p}+\epsilon_t
\]
</li>
<li>A time series is autoregressive of order \(p\) with moving average noise (ARMA) of order \(q\) if
\[y_t=\alpha_1y_{t-1}+\cdots+\alpha_py_{t-p}+\beta_0\epsilon_t+\beta_1\epsilon_{t-1}+\cdots+\beta_q\epsilon_{t-q}
\]
</li>
<li>An autoregressive integrated moving average model (ARIMA(\(p,d,q\))) is a time series that its \(d\)-th difference is an ARMA(\(p,q\)).</li>
</ol>
<h2><a id="unsupervised-learning-a-name-unsupervisedlearning-a" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Unsupervised Learning <a name="UnsupervisedLearning"></a></h2>
</div></body></html>