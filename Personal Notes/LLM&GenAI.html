<!doctype html><html><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1"><title>LLM&GenAI</title><style>/* copy from https://github.com/sindresorhus/github-markdown-css/ */

html,body{background-color: #2d2d2d;}

.markdown-body {
  -ms-text-size-adjust: 100%;
  -webkit-text-size-adjust: 100%;
  line-height: 1.5;
  color: #cccccc;
  font-family: -apple-system,BlinkMacSystemFont,Segoe UI,Helvetica,Arial,sans-serif,Apple Color Emoji,Segoe UI Emoji;
  font-size: 16px;
  line-height: 1.5;
  word-wrap: break-word;
}

.markdown-body .octicon {
  display: inline-block;
  fill: currentColor;
  vertical-align: text-bottom;
}

.markdown-body figure{margin:0;padding:0; display:table;}
.markdown-body figure figcaption{font-size:92%; text-align:center; color:#999999;}

.markdown-body .anchor {
  float: left;
  line-height: 1;
  margin-left: -20px;
  padding-right: 4px;
}

.markdown-body .anchor:focus {
  outline: none;
}

.markdown-body h1 .octicon-link,
.markdown-body h2 .octicon-link,
.markdown-body h3 .octicon-link,
.markdown-body h4 .octicon-link,
.markdown-body h5 .octicon-link,
.markdown-body h6 .octicon-link {
  color: #66cccc;
  vertical-align: middle;
  visibility: hidden;
}

.markdown-body h1:hover .anchor,
.markdown-body h2:hover .anchor,
.markdown-body h3:hover .anchor,
.markdown-body h4:hover .anchor,
.markdown-body h5:hover .anchor,
.markdown-body h6:hover .anchor {
  text-decoration: none;
}

.markdown-body details {
  display: block;
}

.markdown-body summary {
  display: list-item;
}

.markdown-body a {
  background-color: initial;
}

.markdown-body a:active,
.markdown-body a:hover {
  outline-width: 0;
}

.markdown-body strong {
  font-weight: inherit;
  font-weight: bolder;
}
.markdown-body strong{
  color: #f99157;
}
.markdown-body em{
  color: #ffcc66;
}

.markdown-body h1 {
  font-size: 2em;
  margin: .67em 0;
}

.markdown-body img {
  border-style: none;
}

.markdown-body code,
.markdown-body kbd,
.markdown-body pre {
  font-family: monospace,monospace;
  font-size: 1em;
}

.markdown-body hr {
  box-sizing: initial;
  height: 0;
  overflow: visible;
}

.markdown-body input {
  font: inherit;
  margin: 0;
}

.markdown-body input {
  overflow: visible;
}

.markdown-body [type=checkbox] {
  box-sizing: border-box;
  padding: 0;
}

.markdown-body * {
  box-sizing: border-box;
}

.markdown-body input {
  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
}

.markdown-body a {
  color: #99cc99;
  text-decoration: none;
}
.markdown-body mjx-container[jax="SVG"] > svg a{fill:#99cc99;stroke: #99cc99;}

.markdown-body a:hover {
  text-decoration: underline;
}

.markdown-body strong {
  font-weight: 600;
}

.markdown-body hr:after,
.markdown-body hr:before {
  display: table;
  content: "";
}

.markdown-body hr:after {
  clear: both;
}

.markdown-body table {
  border-spacing: 0;
  border-collapse: collapse;
}

.markdown-body td,
.markdown-body th {
  padding: 0;
}

.markdown-body details summary {
  cursor: pointer;
}

.markdown-body kbd {
  display: inline-block;
  padding: 3px 5px;
  font: 12px SFMono-Regular,Consolas,Liberation Mono,Menlo,monospace;
  line-height: 12px;
  color: #999999;
  vertical-align: middle;
  background-color: #333333;
  border: 1px solid #494949;
  border-radius: 3px;
}

.markdown-body h1,
.markdown-body h2,
.markdown-body h3,
.markdown-body h4,
.markdown-body h5,
.markdown-body h6 {
  margin-top: 0;
  margin-bottom: 0;
}

.markdown-body h1 {
  font-size: 32px;
}

.markdown-body h1,
.markdown-body h2 {
  font-weight: 600;
}

.markdown-body h2 {
  font-size: 24px;
}

.markdown-body h3 {
  font-size: 20px;
}

.markdown-body h3,
.markdown-body h4 {
  font-weight: 600;
}

.markdown-body h4 {
  font-size: 16px;
}

.markdown-body h5 {
  font-size: 14px;
}

.markdown-body h5,
.markdown-body h6 {
  font-weight: 600;
}

.markdown-body h6 {
  font-size: 12px;
}

.markdown-body p {
  margin-top: 0;
  margin-bottom: 10px;
}

.markdown-body blockquote {
  margin: 0;
}

.markdown-body ol,
.markdown-body ul {
  padding-left: 0;
  margin-top: 0;
  margin-bottom: 0;
}

.markdown-body ol ol,
.markdown-body ul ol {
  list-style-type: lower-roman;
}

.markdown-body ol ol ol,
.markdown-body ol ul ol,
.markdown-body ul ol ol,
.markdown-body ul ul ol {
  list-style-type: lower-alpha;
}

.markdown-body dd {
  margin-left: 0;
}

.markdown-body code,
.markdown-body pre {
  font-family: SFMono-Regular,Consolas,Liberation Mono,Menlo,monospace;
  font-size: 12px;
}

.markdown-body pre {
  margin-top: 0;
  margin-bottom: 0;
}

.markdown-body input::-webkit-inner-spin-button,
.markdown-body input::-webkit-outer-spin-button {
  margin: 0;
  -webkit-appearance: none;
  appearance: none;
}

.markdown-body:after,
.markdown-body:before {
  display: table;
  content: "";
}

.markdown-body:after {
  clear: both;
}

.markdown-body>:first-child {
  margin-top: 0!important;
}

.markdown-body>:last-child {
  margin-bottom: 0!important;
}

.markdown-body a:not([href]) {
  color: inherit;
  text-decoration: none;
}

.markdown-body blockquote,
.markdown-body details,
.markdown-body dl,
.markdown-body ol,
.markdown-body p,
.markdown-body pre,
.markdown-body table,
.markdown-body ul {
  margin-top: 0;
  margin-bottom: 16px;
}

.markdown-body hr {
  height: .25em;
  padding: 0;
  margin: 24px 0;
  background-color: #494949;
  border: 0;
}

.markdown-body blockquote {
  padding: 0 1em;
  color: #9b9b9b;
  border-left: .25em solid #f2777a;
}

.markdown-body blockquote>:first-child {
  margin-top: 0;
}

.markdown-body blockquote>:last-child {
  margin-bottom: 0;
}

.markdown-body h1,
.markdown-body h2,
.markdown-body h3,
.markdown-body h4,
.markdown-body h5,
.markdown-body h6 {
  margin-top: 24px;
  margin-bottom: 16px;
  font-weight: 600;
  line-height: 1.25;
}

.markdown-body h1 {
  font-size: 2em;
}

.markdown-body h1,
.markdown-body h2 {
  padding-bottom: .3em;
  border-bottom: 1px solid #434343;
  color: #66cccc;
}

.markdown-body h2 {
  font-size: 1.5em;
  color: #66cccc;
}

.markdown-body h3 {
  font-size: 1.25em;
  color: #66cccc;
}

.markdown-body h4 {
  font-size: 1em;
  color: #66cccc;
}

.markdown-body h5 {
  font-size: .875em;
  color: #66cccc;
}

.markdown-body h6 {
  font-size: .85em;
  color: #66cccc;
}

.markdown-body ol,
.markdown-body ul {
  padding-left: 2em;
}

.markdown-body ol ol,
.markdown-body ol ul,
.markdown-body ul ol,
.markdown-body ul ul {
  margin-top: 0;
  margin-bottom: 0;
}

.markdown-body li {
  word-wrap: break-all;
}

.markdown-body li>p {
  margin-top: 16px;
}

.markdown-body li+li {
  margin-top: .25em;
}

.markdown-body dl {
  padding: 0;
}

.markdown-body dl dt {
  padding: 0;
  margin-top: 16px;
  font-size: 1em;
  font-style: italic;
  font-weight: 600;
}

.markdown-body dl dd {
  padding: 0 16px;
  margin-bottom: 16px;
}

.markdown-body table {
  display: block;
  width: 100%;
  overflow: auto;
}

.markdown-body table th {
  font-weight: 600;
}

.markdown-body table td,
.markdown-body table th {
  padding: 6px 13px;
  border: 1px solid #717171;
}

.markdown-body table tr {
  background-color: #2d2d2d;
  border-top: 1px solid #717171;
}

.markdown-body table th {
  background-color: #434343;
}

.markdown-body table tr:nth-child(2n) {
  background-color: #323232;
}

.markdown-body img,.markdown-body video {
  max-width: 100%;
  box-sizing: initial;
}

.markdown-body img[align=right] {
  padding-left: 20px;
}

.markdown-body img[align=left] {
  padding-right: 20px;
}

.markdown-body code {
  padding: .2em .4em;
  margin: 0;
  font-size: 85%;
  background-color: #333333;
  color: #999999;
  border-radius: 3px;
}

.markdown-body pre {
  word-wrap: normal;
}

.markdown-body pre>code {
  padding: 0;
  margin: 0;
   font-size: 100%;
  word-break: normal;
  white-space: pre;
  background: transparent;
  border: 0;
}

.markdown-body .highlight {
  margin-bottom: 16px;
}

.markdown-body .highlight pre {
  margin-bottom: 0;
  word-break: normal;
}

.markdown-body .highlight pre,
.markdown-body pre {
  padding: 16px;
  overflow: auto;
  font-size: 85%;
  line-height: 1.45;
  background-color: #333333;
  border-radius: 3px;
}

.markdown-body pre code {
  display: inline;
  max-width: auto;
  padding: 0;
  margin: 0;
  overflow: visible;
  line-height: inherit;
  word-wrap: normal;
  background-color: initial;
  border: 0;
  color: #999999;
}

.markdown-body .task-list-item {
  list-style-type: none;
}

.markdown-body .task-list-item+.task-list-item {
  margin-top: 3px;
}

.markdown-body .task-list-item input {
  margin: 0 .2em .25em -1.6em;
  vertical-align: middle;
}

.markdown-body .task-list-item input[type="checkbox"]{
-webkit-appearance: none;-moz-appearance: none;appearance: none;
width: 14px; height: 14px;outline: none;
border: 1px solid #99cc99;border-radius: 2px; 
}
.markdown-body .task-list-item input[type="checkbox"]:checked {
  background:no-repeat center/80% url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20viewBox%3D%220%200%20512%20512%22%3E%3Cpath%20fill%3D%22%2399cc99%22%20d%3D%22M173.898%20439.404l-166.4-166.4c-9.997-9.997-9.997-26.206%200-36.204l36.203-36.204c9.997-9.998%2026.207-9.998%2036.204%200L192%20312.69%20432.095%2072.596c9.997-9.997%2026.207-9.997%2036.204%200l36.203%2036.204c9.997%209.997%209.997%2026.206%200%2036.204l-294.4%20294.401c-9.998%209.997-26.207%209.997-36.204-.001z%22%2F%3E%3C%2Fsvg%3E") ;
}

.markdown-body section.footnotes{
    margin-top:48px;
    border-top:solid 1px #494949;
    padding-top:0px;
}

@media (prefers-color-scheme: dark) {
  .markdown-body mark{color: #111;}
}

/* PrismJS 1.23.0
https://prismjs.com/download.html#themes=prism&languages=markup+css+clike+javascript */
/**
 * prism.js default theme for JavaScript, CSS and HTML
 * Based on dabblet (http://dabblet.com)
 * @author Lea Verou
 */


code[class*="language-"],
pre[class*="language-"] {
    color: black;
    background: none;
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
    text-align: left;
    white-space: pre;
    word-spacing: normal;
    word-break: normal;
    word-wrap: normal;
    -moz-tab-size: 4;
    -o-tab-size: 4;
    tab-size: 4;

    -webkit-hyphens: none;
    -moz-hyphens: none;
    -ms-hyphens: none;
    hyphens: none;
}

@media print {
    code[class*="language-"],
    pre[class*="language-"] {
        text-shadow: none;
    }
}

/* Code blocks */
pre[class*="language-"] {
    padding: 1em;
    margin: .5em 0;
    overflow: auto;
}

:not(pre) > code[class*="language-"],
pre[class*="language-"] {
    background-color: #333333;
}

/* Inline code */
:not(pre) > code[class*="language-"] {
    padding: .1em;
    border-radius: .3em;
    white-space: normal;
}

.token.comment,
.token.prolog,
.token.doctype,
.token.cdata {
    color: #48be66;
}

.token.punctuation {
    color: #8b86c9;
}

.token.namespace {
    opacity: .7;
}

.token.property,
.token.tag,
.token.boolean,
.token.number,
.token.constant,
.token.symbol,
.token.deleted {
    color: #8b86c9;
}

.token.selector,
.token.attr-name,
.token.string,
.token.char,
.token.builtin,
.token.inserted {
    color: #e6424b;
}

.token.operator,
.token.entity,
.token.url,
.language-css .token.string,
.style .token.string {
    color: #$$codeBlockColor$$;
}

.token.atrule,
.token.attr-value,
.token.keyword {
    color: #c33795;
}

.token.function,
.token.class-name {
    color: #67878e;
}

.token.regex,
.token.important,
.token.variable {
    color: #d38e63;
}

.token.important,
.token.bold {
    font-weight: bold;
}
.token.italic {
    font-style: italic;
}

.token.entity {
    cursor: help;
}


pre[class*="language-"].line-numbers {
  position: relative;
  padding-left: 3.8em;
  counter-reset: linenumber;
}

pre[class*="language-"].line-numbers > code {
  position: relative;
  white-space: inherit;
}

.line-numbers .line-numbers-rows {
  position: absolute;
  pointer-events: none;
  top: 0;
  font-size: 100%;
  left: -3.8em;
  width: 3em; /* works for line-numbers below 1000 lines */
  letter-spacing: -1px;
  border-right: 1px solid #6b6b6b;

  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;

}

  .line-numbers-rows > span {
    display: block;
    counter-increment: linenumber;
  }

    .line-numbers-rows > span:before {
      content: counter(linenumber);
      color: #6b6b6b;
      display: block;
      padding-right: 0.8em;
      text-align: right;
    }


</style><style>.mweb-charts{background:#fff;}
body{ box-sizing: border-box;
    margin: 0 auto;}
@media print{
    pre, code, pre code {
     overflow: visible !important;
     white-space: pre-wrap !important;       /* css-3 */
     white-space: -moz-pre-wrap !important;  /* Mozilla, since 1999 */
     white-space: -pre-wrap !important;      /* Opera 4-6 */
     white-space: -o-pre-wrap !important;    /* Opera 7 */
     word-wrap: break-word !important;       /* Internet Explorer 5.5+ */
    }
    html,body{margin:0;padding:4px;}
}



div.code-toolbar {
  position: relative;
}

div.code-toolbar > .toolbar {
  position: absolute;
  z-index: 10;
  top: .3em;
  right: .2em;
  transition: opacity 0.3s ease-in-out;
  opacity: 0;
}

div.code-toolbar:hover > .toolbar {
  opacity: 1;
}

/* Separate line b/c rules are thrown out if selector is invalid.
   IE11 and old Edge versions don't support :focus-within. */
div.code-toolbar:focus-within > .toolbar {
  opacity: 1;
}

div.code-toolbar > .toolbar > .toolbar-item {
  display: inline-block;
}

div.code-toolbar > .toolbar > .toolbar-item > a {
  cursor: pointer;
}

div.code-toolbar > .toolbar > .toolbar-item > button {
  background: none;
  border: 0;
  color: inherit;
  font: inherit;
  line-height: normal;
  overflow: visible;
  padding: 0;
  -webkit-user-select: none; /* for button */
  -moz-user-select: none;
  -ms-user-select: none;
}

div.code-toolbar > .toolbar > .toolbar-item > a,
div.code-toolbar > .toolbar > .toolbar-item > button,
div.code-toolbar > .toolbar > .toolbar-item > span {
  color: inherit;
  font-size: .8em;
  padding: 4px .5em;
  background: #f5f2f0;
  background: rgba(224, 224, 224, 0.4);
  box-shadow: 0 2px 0 0 rgba(0,0,0,0.2);
  border-radius: .5em;
}

div.code-toolbar > .toolbar > .toolbar-item > a:hover,
div.code-toolbar > .toolbar > .toolbar-item > a:focus,
div.code-toolbar > .toolbar > .toolbar-item > button:hover,
div.code-toolbar > .toolbar > .toolbar-item > button:focus,
div.code-toolbar > .toolbar > .toolbar-item > span:hover,
div.code-toolbar > .toolbar > .toolbar-item > span:focus {
  color: inherit;
  text-decoration: none;
}
</style><script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/prism.min.js"></script><script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/plugins/line-numbers/prism-line-numbers.min.js"></script><script>!function(){if("undefined"!=typeof Prism&&"undefined"!=typeof document){var e=[],t={},n=function(){};Prism.plugins.toolbar={};var a=Prism.plugins.toolbar.registerButton=function(n,a){var r;r="function"==typeof a?a:function(e){var t;return"function"==typeof a.onClick?((t=document.createElement("button")).type="button",t.addEventListener("click",(function(){a.onClick.call(this,e)}))):"string"==typeof a.url?(t=document.createElement("a")).href=a.url:t=document.createElement("span"),a.className&&t.classList.add(a.className),t.textContent=a.text,t},n in t?console.warn('There is a button with the key "'+n+'" registered already.'):e.push(t[n]=r)},r=Prism.plugins.toolbar.hook=function(a){var r=a.element.parentNode;var l=a.element.classList;if(l.contains('language-mermaid') || l.contains('language-echarts') || l.contains('language-plantuml')){return;} if(r&&/pre/i.test(r.nodeName)&&!r.parentNode.classList.contains("code-toolbar")){var o=document.createElement("div");o.classList.add("code-toolbar"),r.parentNode.insertBefore(o,r),o.appendChild(r);var i=document.createElement("div");i.classList.add("toolbar");var l=e,d=function(e){for(;e;){var t=e.getAttribute("data-toolbar-order");if(null!=t)return(t=t.trim()).length?t.split(/\s*,\s*/g):[];e=e.parentElement}}(a.element);d&&(l=d.map((function(e){return t[e]||n}))),l.forEach((function(e){var t=e(a);if(t){var n=document.createElement("div");n.classList.add("toolbar-item"),n.appendChild(t),i.appendChild(n)}})),o.appendChild(i)}};a("label",(function(e){var t=e.element.parentNode;if(t&&/pre/i.test(t.nodeName)&&t.hasAttribute("data-label")){var n,a,r=t.getAttribute("data-label");try{a=document.querySelector("template#"+r)}catch(e){}return a?n=a.content:(t.hasAttribute("data-url")?(n=document.createElement("a")).href=t.getAttribute("data-url"):n=document.createElement("span"),n.textContent=r),n}})),Prism.hooks.add("complete",r)}}();</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/plugins/toolbar/prism-toolbar.min.css"><script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/plugins/copy-to-clipboard/prism-copy-to-clipboard.min.js"></script><script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/plugins/autoloader/prism-autoloader.min.js"></script><style>div.code-toolbar > .toolbar > .toolbar-item > a, div.code-toolbar > .toolbar > .toolbar-item > button, div.code-toolbar > .toolbar > .toolbar-item > span {padding: 4px .5em; background: #f5f2f0; background: rgba(224, 224, 224, 0.4);}</style><script>window.MathJax = {     tex: { tags: 'ams', displayMath: [ ['\\[', '\\]'] ] } ,     startup: {     pageReady() {       return MathJax.startup.defaultPageReady().then(function () {          window.mweb_mathjax_ready_val = 'yes';          if(window.mweb_mathjax_ready !== undefined){ mweb_mathjax_ready(); }       });     }   }};document.addEventListener('DOMContentLoaded', function(event) {    if (typeof Prism != 'undefined') {         Prism.highlightAll();     }});window.mweb_mathjax_ready_val = '';function theMWebMathJaxRenderIsReady(key){ return window.mweb_mathjax_ready_val; }</script><script>window.MathJax = { tex: { tags: 'ams', displayMath: [ ['\\[', '\\]'] ] } }; </script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"></script> <style>body{max-width:808px; padding:24px;}</style></head><body><div id='markdown_content' class='markdown-body'><h1><a id="large-language-model-and-generative-ai" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Large Language Model and Generative AI</h1>
<p>A <em>language model</em> is model that estimating the probability \(P(s)\) of occurrence of a sentence \(s\).</p>
<h2><a id="recurrent-neural-network" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Recurrent Neural Network</h2>
<p>A <em>recurrent neural network (RNN)</em> is a class of neural networks that discover the sequential nature of the input data. Inputs could be text, speech, time series, etc.</p>
<p>The architecture of a simplest RNN is</p>
\[h_t=\tanh(W_{h}\cdot h_{t-1}+W_{x}\cdot x_{t}+b)
\]
<p>Types of RNN</p>
<ul>
<li>one-to-one: traditional neural network</li>
<li>one-to-many: music generation</li>
<li>many-to-one: sentiment classification</li>
<li>many-to-many (equal): name entity recognition</li>
<li>many-to-many (unequal): machine translation</li>
</ul>
<p>The loss function is the sum of losses of all time steps.</p>
<p>Due to the number of layers in the deep neural network, the gradients as  continuous matrix multiplications because of the chain rule will shrink exponentially if they start from small values (&lt;1) and will blow up if they start from large values (&gt;1). This is called the <em>vanishing or exploding gradient problem</em>.</p>
<h2><a id="long-short-term-memory" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Long Short Term Memory</h2>
<p><em>Long short term memory (LSTM)</em> is a special kind of RNN, designed to avoid long-term dependency problem. All RNN have the form of a chain of repeating modules of neural network. In standard RNNs, this repeating module has a single <code>tanh</code> layer, whereas LSRMs has four, interacting as below</p>
\[\begin{cases}
f_t=\sigma(W_{fh}\cdot h_{t-1}+W_{fx}\cdot x_t+b_f) \\
i_t=\sigma(W_{ih}\cdot h_{t-1}+W_{ix}\cdot x_t+b_i) \\
o_t=\sigma(W_{oh}\cdot h_{t-1}+W_{ox}\cdot x_t+b_o) \\
\tilde C_t=\tanh(W_{Ch}\cdot h_{t-1}+W_{Cx}\cdot x_t+b_C) \\
C_t=f_t\cdot C_{t-1}+i_t\cdot \tilde C_t \\
h_t=o_t\cdot \tanh(C_t)
\end{cases}
\]
<p>Here \(\sigma\) is the sigmoid function, \(f_t, i_t, o_t\) are the forget, input, output gates, \(C_t\) is the cell state, and \(h_t\) is the hidden state.</p>
<h2><a id="gated-recurrent-unit" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Gated Recurrent Unit</h2>
<p><em>Gated recurrent unit (GRU)</em> is a variant of LSTM that has a simpler internal structure, and uses gating mechanisms to control and manage the flow of information between cells in the neural network.</p>
\[\begin{cases}
z_t=\sigma(W_{zh}\cdot h_{t-1}+W_{zx}\cdot x_t) \\
r_t=\sigma(W_{rh}\cdot h_{t-1}+W_{rx}\cdot x_t) \\
\tilde h_t=\tanh(W_{hh}\cdot r_t h_{t-1}+W_{hx}\cdot x_t) \\
h_t=(1-z_t)\cdot h_{t-1}+z_t\cdot \tilde h_t \\
\end{cases}
\]
<p>Here \(r_t,\tilde h_t\) are the relevance, update gates.</p>
<p>Other variants includes</p>
<table>
<thead>
<tr>
<th>Bidirectional (BRNN)</th>
<th>Deep (DRNN)</th>
</tr>
</thead>
<tbody>
<tr>
<td><img src="https://stanford.edu/~shervine/teaching/cs-230/illustrations/bidirectional-rnn-ltr.png?e3e66fae56ea500924825017917b464a" alt="BRNN" /></td>
<td><img src="https://stanford.edu/~shervine/teaching/cs-230/illustrations/deep-rnn-ltr.png?f57da6de44ddd4709ad3b696cac6a912" alt="DRNN" /></td>
</tr>
</tbody>
</table>
<h2><a id="word-representations" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Word representations</h2>
<p>There are two main ways of presenting words</p>
<ol>
<li>1-hot representation, denoted \(o_w\).</li>
<li>word embedding, denoted \(e_w\).</li>
</ol>
<p>The <em>embedding matrix</em> \(E\) such that \(e_w = Eo_w\) can be learnt using target/context likelihood models by defining the conditional probability as</p>
\[p(w_o|w_i)=\frac{\exp(e_{w_o}\cdot e_{w_i})}{\sum_{w\in V}\exp(e_w\cdot e_{w_i})}
\]
<h3><a id="word2vec" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Word2Vec</h3>
<p><em>word2vec</em> is a framework aimed at learning word embeddings by estimating the likelihood that a given word is surrounded by other words, popular models include</p>
<ol>
<li><em>skip-gram</em> maximize
\[\frac{1}{T}\sum_{t=1}^T\sum_{-c\leq j\leq c,j\neq0}\log p(w_{t+j}|w_t)
\]
</li>
<li><em>continuous bag-of-words (CBOW)</em> maximize
\[\frac{1}{T}\sum_{t=1}^T\sum_{-c\leq j\leq c,j\neq0}\log p(w_t|w_{t+j})
\]
</li>
</ol>
<p>Computing softmax probabilities for all words is computationally expensive. To address this, we could perform the computations in some other ways.</p>
<p><em>Hierarchical softmax</em> is a way to make the calculation of the sum in the denominator of the conditional probability faster is with the help of a binary tree structure. All the leaves nodes represent words, and internal nodes measure connections between children nodes. Concretely, let \(n(w_o,k)\) to be the node on the unique path from root to \(w_o\) with \(w_o\) being its \(k\)-th generation descendant, stored with the node a weight vector \(v_n\), we define</p>
\[\begin{align*}
p(n\to\text{left}|w_i)&amp;=\sigma(v_n\cdot e_i)\\
p(n\to\text{right}|w_i)&amp;=1-p(n\to\text{left}|w_i)=\sigma(-v_n\cdot e_i)
\end{align*}
\]
<p>and</p>
\[p(w_o|w_i)=\prod_{k}p(n(w_o,k+1)\to n(w_o,k))
\]
<p>The internal nodes embeddings are learnt during model training. The tree structure helps greatly reduce the complexity of the denominator estimation from \(O(V)\) to \(O(\log V)\).</p>
<p><em>Negative sampling</em> transforms the objective of predicting words into a binary classification problem, the model is trained to distinguish between positive (actual context words, label \(y=1\)) and negative (randomly sampled noise, label \(y=0\)) examples. Concretely, we use probabilities</p>
\[\begin{align*}
p(y=1|w_o,w_i)&amp;=\sigma(e_o\cdot e_i)\\
p(y=0|w_o,w_i)&amp;=1-\sigma(e_o\cdot e_i)=\sigma(-e_o\cdot e_i)
\end{align*}
\]
<p>Here \(\sigma(x)=\dfrac{1}{1+e^{-x}}\) is the sigmoidal function. We define the loss to be</p>
\[\mathcal L=-\sum_{i,o}\log p(y=1|w_o,w_i)+\sum_{i,o}\sum_{w\sim P_n}\log p(y=0|w,w_i)
\]
<p>Here \(w\sim P_n\) is a negative sampled noised words, and the noise distribution \(P_n(w)=U(w)^{3/4}/Z\) is the <em>Zipf's law</em>, \(U\) meaning word frequency.</p>
<h4><a id="pros-cons" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Pros &amp; Cons</h4>
<ol>
<li>skip-gram is better suited for rare words because rare words often have unique contexts.</li>
<li>skip-gram is known for capturing fine-grained semantic relationships between words. Since it learns separate embeddings for each word, which can represent subtle semantic nuances and capture relationships between words that may appear in diverse contexts.</li>
<li>CBOW is faster to train. Since it aggregates context information from multiple words to predict a single target word. This approach tends to be computationally more efficient, especially for large vocabularies.</li>
<li>CBOW performs better for frequent words because it average context vectors. Frequent words tend to occur in various contexts, and CBOW can effectively aggregate this information to learn robust representations for these words.</li>
<li>skip-gram tends to perform better with larger datasets, while CBOW may perform better with smaller datasets.</li>
</ol>
<h3><a id="glove" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>GloVe</h3>
<p><em>GloVe (global vectors)</em> is a word embedding technique that uses a co-occurence matrix \(X\) where each \(X_{ij}\) denotes the number of times \(w_j\) occurs in the context of \(w_i\). The co-occurrence probability is defined to be</p>
\[P_{ij}=p(w_j|w_i)=\frac{X_{ij}}{X_i}
\]
<p>Here \(X_i=\sum_kX_{ik}\) is the number of occurrence of \(w_i\). Define</p>
\[F(w_i,w_j,w_k)=\frac{P_{ik}}{P_{jk}}
\]
<p>This ratio shed some light on the corelation of the probe word \(w_k\) with the words \(w_i\) and \(w_j\). If the ratio is large, then the probe word is related to \(w_i\) but not \(w_j\) and vice versa, it equals to 1, then \(w_k\) is likely to be unrelated to both \(w_i,w_j\). Since we would like the linearity on the word embeddings, We expect \(F\) to satisfy</p>
\[F((e_{w_i}-e_{w_j})\cdot e_{w_k})=\frac{F(e_{w_i}\cdot e_{w_k})}{F(e_{w_j}\cdot e_{w_k})}=\frac{P_{ik}}{P_{jk}}
\]
<p>The solution would be \(F=\exp\), so</p>
\[F(e_{w_i}\cdot e_{w_k})=\exp(e_{w_i}\cdot e_{w_k})
\]
<p>Hence</p>
\[e_{w_i}\cdot e_{w_k}=\log P_{ik}=\log X_{ik} - \log X_i
\]
<p>Since \(\log X_i\) is independent of \(k\) and break the symmetry between \(i,k\), we can add a bias term \(b_{w_i}\) to \(e_{w_i}\) to absorb \(-\log X_i\) and add \(b_{w_k}\) to \(e_{w_k}\) to make it symmetric. The cost function can then be defined simply as</p>
\[J(\theta)=\frac{1}{2}\sum_{i,j}f(X_{ij})(e_{w_i}\cdot e_{w_j}+b_{w_i}+b_{w_j}'-\log X_{ij})^2
\]
<p>Where \(f(c)\) is a weighting function should be non-decreasing and go to zero as \(c\to 0\). For example, with some adjustable \(c_{\max}\)</p>
\[f(c)=\begin{cases}
\left(c/c_{\max}\right)^\alpha, &amp;\text{if $c&lt;c_{\max}$}\\
1, &amp;\text{otherwise}
\end{cases}
\]
<p>Given the symmetry of \(e_{w_i},e_{w_j}\), the final word embedding is \(\dfrac{e_{w_i}+e_{w_j}}{2}\).</p>
<h3><a id="perplxity" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Perplxity</h3>
</div></body></html>